{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Coding skills with general data science use case"
      ],
      "metadata": {
        "id": "xeD3an2REFmM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X2S_4LnNajk",
        "outputId": "c7c5d92c-cef8-41f6-dc68-e1cd34dc9842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=ad5ca079392d31ae5a3321610778a018f3fcc6adcd142b982d30ebb6ed8fff36\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "spark = SparkSession.builder.appName(\"TestApp\").getOrCreate()"
      ],
      "metadata": {
        "id": "2FazaS6-Nfvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "billing = [\n",
        "        {'Customer': 'Bob', 'Paid Date': '2022-01-31', 'Paid Amount': '100'},\n",
        "        {'Customer': 'Bob', 'Paid Date': '2022-02-25', 'Paid Amount': '140'},\n",
        "        {'Customer': 'Bob', 'Paid Date': '2022-03-15', 'Paid Amount': '120'},\n",
        "        {'Customer': 'Lee', 'Paid Date': '2022-01-15', 'Paid Amount': '150'},\n",
        "        {'Customer': 'Lee', 'Paid Date': '2022-02-28', 'Paid Amount': '135'},\n",
        "        {'Customer': 'Nok', 'Paid Date': '2022-04-13', 'Paid Amount': '200'},\n",
        "       ]\n",
        "\n",
        "extraBills = [\n",
        "    {'Customer': 'Nok', 'Paid Date': '2022-05-31', 'Paid Amount': '201'},\n",
        "    {'Customer': 'Bob', 'Paid Date': '2022-03-25', 'Paid Amount': '160'}\n",
        "]"
      ],
      "metadata": {
        "id": "_oKWPHb6NyPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. How to filter ONLY rows with max “Paid Date” of each “Customer”."
      ],
      "metadata": {
        "id": "_iHYPg3hEI4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "billing_df = spark.createDataFrame(billing)\n",
        "billing_df = billing_df.withColumn(\"Paid Date\", to_date(billing_df[\"Paid Date\"], \"yyyy-MM-dd\"))"
      ],
      "metadata": {
        "id": "hFDbgE97N3SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "billing_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gscbi7Ph-e",
        "outputId": "a8358ef6-29f3-4f0c-8e5e-d494aa9888a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+\n",
            "|Customer|Paid Amount| Paid Date|\n",
            "+--------+-----------+----------+\n",
            "|     Bob|        100|2022-01-31|\n",
            "|     Bob|        140|2022-02-25|\n",
            "|     Bob|        120|2022-03-15|\n",
            "|     Lee|        150|2022-01-15|\n",
            "|     Lee|        135|2022-02-28|\n",
            "|     Nok|        200|2022-04-13|\n",
            "+--------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1_max_date = billing_df.groupBy(\"Customer\").agg(max(\"Paid Date\").alias(\"Max Paid Date\")).withColumnRenamed('Customer', 'Cust')\n",
        "\n",
        "q1_max_date = q1_max_date.join(billing_df, (billing_df[\"Customer\"] == q1_max_date[\"Cust\"]) & (billing_df[\"Paid Date\"] == q1_max_date[\"Max Paid Date\"]), how='inner')\\\n",
        "              .select('Cust', 'Max Paid Date', 'Paid Amount').withColumnRenamed('Cust', 'Customer').withColumnRenamed('Max Paid Date','Paid Date')"
      ],
      "metadata": {
        "id": "aYSZXLXYPpRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1_max_date.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvA_4V_EPrTV",
        "outputId": "349e8129-7294-4eb7-b42c-112ad772a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+-----------+\n",
            "|Customer| Paid Date|Paid Amount|\n",
            "+--------+----------+-----------+\n",
            "|     Bob|2022-03-15|        120|\n",
            "|     Nok|2022-04-13|        200|\n",
            "|     Lee|2022-02-28|        135|\n",
            "+--------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. How to combine the “Billing” DataFrame with “ExtraBills” as below:"
      ],
      "metadata": {
        "id": "OIYJsh5LEPCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extra_billing_df = spark.createDataFrame(extraBills)\n",
        "extra_billing_df = extra_billing_df.withColumn(\"Paid Date\", to_date(extra_billing_df[\"Paid Date\"], \"yyyy-MM-dd\"))"
      ],
      "metadata": {
        "id": "N9ytmcSuYkYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_billing_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHeIdFlaEa0a",
        "outputId": "408bb28b-4cf0-4eff-cf29-4e693c3b99c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+\n",
            "|Customer|Paid Amount| Paid Date|\n",
            "+--------+-----------+----------+\n",
            "|     Nok|        201|2022-05-31|\n",
            "|     Bob|        160|2022-03-25|\n",
            "+--------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "billing_concat = billing_df.unionByName(extra_billing_df)\n",
        "billing_concat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPycTqj-E9Yt",
        "outputId": "e413dc17-3aba-4052-bf1b-5d86685aeb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+\n",
            "|Customer|Paid Amount| Paid Date|\n",
            "+--------+-----------+----------+\n",
            "|     Bob|        100|2022-01-31|\n",
            "|     Bob|        140|2022-02-25|\n",
            "|     Bob|        120|2022-03-15|\n",
            "|     Lee|        150|2022-01-15|\n",
            "|     Lee|        135|2022-02-28|\n",
            "|     Nok|        200|2022-04-13|\n",
            "|     Nok|        201|2022-05-31|\n",
            "|     Bob|        160|2022-03-25|\n",
            "+--------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Find the number of days between “Paid Date” of each “Customer” from “Billing”."
      ],
      "metadata": {
        "id": "GyOAwtx-GIkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"Customer\").orderBy(\"Paid Date\")\n",
        "between_date = billing_df.withColumn(\"Days Difference\", datediff(col(\"Paid Date\"), lag(col(\"Paid Date\")).over(windowSpec)))"
      ],
      "metadata": {
        "id": "UMP2oXhQFINv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "between_date.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZrbXOjzGrDG",
        "outputId": "1758471c-004c-4b89-f30f-a7b089cee819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+---------------+\n",
            "|Customer|Paid Amount| Paid Date|Days Difference|\n",
            "+--------+-----------+----------+---------------+\n",
            "|     Bob|        100|2022-01-31|           NULL|\n",
            "|     Bob|        140|2022-02-25|             25|\n",
            "|     Bob|        120|2022-03-15|             18|\n",
            "|     Lee|        150|2022-01-15|           NULL|\n",
            "|     Lee|        135|2022-02-28|             44|\n",
            "|     Nok|        200|2022-04-13|           NULL|\n",
            "+--------+-----------+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VYN-R0XTGsU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}