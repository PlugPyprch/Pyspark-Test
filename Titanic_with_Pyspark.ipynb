{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "c_Ais72uWqfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA5hcZtjWGot",
        "outputId": "87d2f368-69c1-4c1b-c764-dead3e447212"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "nfDYZJqkWuGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHx5mWg7WHaV",
        "outputId": "afcfffa9-0211-4025-a2da-5e8cdf9443cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "spark = SparkSession.builder.appName(\"Titanic\").getOrCreate()"
      ],
      "metadata": {
        "id": "boOnXWhiWiJN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df = pd.read_excel('/content/drive/MyDrive/Phutthabut_test/titanic 1.xlsx')"
      ],
      "metadata": {
        "id": "tNK-x08TWptP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = spark.createDataFrame(pd_df)"
      ],
      "metadata": {
        "id": "YlnF9c27XVu-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD4-4sX6X6oO",
        "outputId": "32dcad44-0546-4df3-95d7-105a5b2c2fef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|  NaN|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|  NaN|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|  NaN|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTjH8TJCYFwl",
        "outputId": "db0067fc-7f78-4722-a803-0f2b05422c1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: long (nullable = true)\n",
            " |-- Survived: long (nullable = true)\n",
            " |-- Pclass: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: long (nullable = true)\n",
            " |-- Parch: long (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast long to int\n",
        "pyspark_df = pyspark_df.withColumn(\"PassengerId\", col(\"PassengerId\").cast(\"integer\")) \\\n",
        "       .withColumn(\"Survived\", col(\"Survived\").cast(\"integer\")) \\\n",
        "       .withColumn(\"Pclass\", col(\"Pclass\").cast(\"integer\")) \\\n",
        "       .withColumn(\"SibSp\", col(\"SibSp\").cast(\"integer\")) \\\n",
        "       .withColumn(\"Parch\", col(\"Parch\").cast(\"integer\")) \\\n",
        "       .withColumn(\"Age\", col(\"Age\").cast(\"double\")) \\\n",
        "       .withColumn(\"Fare\", col(\"Fare\").cast(\"double\"))"
      ],
      "metadata": {
        "id": "KoOh1T_wmp09"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'rows : {pyspark_df.count()}')\n",
        "print(f'columns : {len(pyspark_df.columns)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcKhRpcHZA4g",
        "outputId": "a5137db1-1538-49f5-fac1-d2c25c55425c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows : 891\n",
            "columns : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "mln4QmcNkeTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Survived').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosqbpEekZBG",
        "outputId": "85846f57-dbb0-4aed-dadc-e4b44a6ed066"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Survived|count|\n",
            "+--------+-----+\n",
            "|       1|  342|\n",
            "|       0|  549|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were 891 passengers on the Titanic, and only 342 survived."
      ],
      "metadata": {
        "id": "T-lt_twakwHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.select('Age', 'Fare').summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwTWsx6Ukuz0",
        "outputId": "eba481d5-e733-4c1e-d600-c09d471ee2ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+------------------+\n",
            "|summary| Age|              Fare|\n",
            "+-------+----+------------------+\n",
            "|  count| 891|               891|\n",
            "|   mean| NaN|32.204207968574615|\n",
            "| stddev| NaN| 49.69342859718091|\n",
            "|    min|0.42|               0.0|\n",
            "|    25%|22.0|            7.8958|\n",
            "|    50%|32.0|           14.4542|\n",
            "|    75%|54.0|              31.0|\n",
            "|    max| NaN|          512.3292|\n",
            "+-------+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Survived').pivot('Sex').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iCQC4IRsS5C",
        "outputId": "f57387f2-528d-4cd1-80c9-4756f0c120f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+\n",
            "|Survived|female|male|\n",
            "+--------+------+----+\n",
            "|       1|   233| 109|\n",
            "|       0|    81| 468|\n",
            "+--------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Survived').pivot('Pclass').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVmu1iEksXEr",
        "outputId": "7669bb8c-f2ce-4356-81fb-9aeda22d45c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+---+\n",
            "|Survived|  1|  2|  3|\n",
            "+--------+---+---+---+\n",
            "|       1|136| 87|119|\n",
            "|       0| 80| 97|372|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, first-class passengers had a higher likelihood of survival than those in second class. Unfortunately, third-class passengers had much worse luck."
      ],
      "metadata": {
        "id": "zZ2aquM8sh01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Survived').pivot('SibSp').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-qQkgO8skd0",
        "outputId": "2ab77f71-c047-4fec-c63f-aa533f579cc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+---+---+---+----+----+\n",
            "|Survived|  0|  1|  2|  3|  4|   5|   8|\n",
            "+--------+---+---+---+---+---+----+----+\n",
            "|       1|210|112| 13|  4|  3|NULL|NULL|\n",
            "|       0|398| 97| 15| 12| 15|   5|   7|\n",
            "+--------+---+---+---+---+---+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Survived').pivot('Embarked').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFABVOmdsvsc",
        "outputId": "400b8d53-ae7d-4781-9cdf-384b46c8227f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----+---+---+\n",
            "|Survived|  C| NaN|  Q|  S|\n",
            "+--------+---+----+---+---+\n",
            "|       1| 93|   2| 30|217|\n",
            "|       0| 75|NULL| 47|427|\n",
            "+--------+---+----+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering and Handle Missing Values"
      ],
      "metadata": {
        "id": "yHZ2aB5Hs5lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.filter(col(\"Age\") == \"NaN\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS2lNxIBlZ-q",
        "outputId": "7e3528db-9a0e-43ed-ab76-ae66441222fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in pyspark_df.columns:\n",
        "  print(f'{cols} : {pyspark_df.filter(col(cols) == \"NaN\").count()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyjIIeQjpUCt",
        "outputId": "013e1b8a-c685-40e3-f270-b8f85ef1df5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId : 0\n",
            "Survived : 0\n",
            "Pclass : 0\n",
            "Name : 0\n",
            "Sex : 0\n",
            "Age : 177\n",
            "SibSp : 0\n",
            "Parch : 0\n",
            "Ticket : 0\n",
            "Fare : 0\n",
            "Cabin : 687\n",
            "Embarked : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seem have null values stand with string of \"NaN\""
      ],
      "metadata": {
        "id": "GxhWb9yUrc9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change \"NaN\" value to be real None\n",
        "for column in pyspark_df.columns:\n",
        "    pyspark_df = pyspark_df.withColumn(column, when(col(column) == 'NaN', None).otherwise(col(column)))"
      ],
      "metadata": {
        "id": "1VxH4MLzpH23"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in pyspark_df.columns:\n",
        "    print(f'{col} : {pyspark_df.filter(pyspark_df[col].isNull()).count()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDtQisbEqn_P",
        "outputId": "f835a0c0-a6ea-4c13-972e-5e72cdc957ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId : 0\n",
            "Survived : 0\n",
            "Pclass : 0\n",
            "Name : 0\n",
            "Sex : 0\n",
            "Age : 177\n",
            "SibSp : 0\n",
            "Parch : 0\n",
            "Ticket : 0\n",
            "Fare : 0\n",
            "Cabin : 687\n",
            "Embarked : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabin feature have over 600 missing values from 891 data, I decided to drop this feature"
      ],
      "metadata": {
        "id": "T_7KNkvhtqIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.select('Fare').summary('mean', '50%', 'max').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N11J2ksDrv4j",
        "outputId": "5c04f75e-d934-49ed-e972-085dcb9b3da0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|              Fare|\n",
            "+-------+------------------+\n",
            "|   mean|32.204207968574615|\n",
            "|    50%|           14.4542|\n",
            "|    max|          512.3292|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Embarked').count().orderBy('count', ascending=False).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHqdobC4NWel",
        "outputId": "668b13df-437b-4c40-ddbb-7730e239613a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Embarked|count|\n",
            "+--------+-----+\n",
            "|       S|  644|\n",
            "+--------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems the most occurring class in Embarked is 'S'"
      ],
      "metadata": {
        "id": "3CCD4vdNNoMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null values in Embarked and Fare with most occurring class and percentile 50 of its column by sequential\n",
        "pyspark_df = pyspark_df.fillna({'Embarked': 'S', 'Fare':14.45})"
      ],
      "metadata": {
        "id": "aK5XD7VEt8CW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For missing values in Age column, I try to impute it with average age of group with title (Mrs tend to be older than Miss)"
      ],
      "metadata": {
        "id": "LIH1IchxO7X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = pyspark_df.withColumn('Title', regexp_extract(pyspark_df['Name'], '([A-Za-z]+)\\.', 1))\n",
        "\n",
        "pyspark_df.groupBy('Title').agg(count('Age'), mean('Age')).sort('count(Age)').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNsF_regu-7G",
        "outputId": "9adc9e80-b652-490e-ca73-9525762c5212"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------------------+\n",
            "|   Title|count(Age)|          avg(Age)|\n",
            "+--------+----------+------------------+\n",
            "|     Don|         1|              40.0|\n",
            "|     Mme|         1|              24.0|\n",
            "|      Ms|         1|              28.0|\n",
            "|Countess|         1|              33.0|\n",
            "|    Lady|         1|              48.0|\n",
            "|    Capt|         1|              70.0|\n",
            "|     Sir|         1|              49.0|\n",
            "|Jonkheer|         1|              38.0|\n",
            "|     Col|         2|              58.0|\n",
            "|    Mlle|         2|              24.0|\n",
            "|   Major|         2|              48.5|\n",
            "|     Rev|         6|43.166666666666664|\n",
            "|      Dr|         6|              42.0|\n",
            "|  Master|        36| 4.574166666666667|\n",
            "|     Mrs|       108|35.898148148148145|\n",
            "|    Miss|       146|21.773972602739725|\n",
            "|      Mr|       398|32.368090452261306|\n",
            "+--------+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last 4 group Mater, Mrs, Miss, Mr have highly repeated"
      ],
      "metadata": {
        "id": "ZxS8C6hYPkwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "title_dict = {'Mr':'Mr', 'Miss':'Miss', 'Mrs':'Mrs', 'Master':'Master', \\\n",
        "             'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\\\n",
        "             'Don': 'Mr', 'Mme': 'Miss', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\\\n",
        "             'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs', \\\n",
        "             'Dr':'Mr', 'Rev':'Mr'}\n",
        "\n",
        "mapping = create_map([lit(x) for x in chain(*title_dict.items())])\n",
        "\n",
        "pyspark_df = pyspark_df.withColumn('Title', mapping[pyspark_df['Title']])"
      ],
      "metadata": {
        "id": "LwFMDNGNvEei"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.groupBy('Title').mean('Age').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcNKm7UVQZOD",
        "outputId": "58ed7e41-86ce-40fb-e49b-ff60b259acc3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "| Title|          avg(Age)|\n",
            "+------+------------------+\n",
            "|  Miss|             21.86|\n",
            "|Master| 4.574166666666667|\n",
            "|    Mr| 33.02272727272727|\n",
            "|   Mrs|35.981818181818184|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_age_dict = {row['Title']: row['avg(Age)'] for row in pyspark_df.groupBy('Title').mean('Age').collect()}"
      ],
      "metadata": {
        "id": "dXC0zw0VRW4Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_age_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wYQwTYBRd6p",
        "outputId": "1a68e499-2622-47b0-83ef-14c565c6fa6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Miss': 21.86,\n",
              " 'Master': 4.574166666666667,\n",
              " 'Mr': 33.02272727272727,\n",
              " 'Mrs': 35.981818181818184}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imputer(df, title, age):\n",
        "    return df.withColumn('Age', \\\n",
        "                         when((df['Age'].isNull()) & (df['Title']==title), \\\n",
        "                              age).otherwise(df['Age']))"
      ],
      "metadata": {
        "id": "I6Fb68cgvS-u"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in mean_age_dict.items():\n",
        "    pyspark_df = imputer(pyspark_df, key, value)"
      ],
      "metadata": {
        "id": "cDJTAz_FRf8J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new column 'FamilySize' combine with Parch and SibSp"
      ],
      "metadata": {
        "id": "MNXX9EJjl4CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = pyspark_df.withColumn('FamilySize', pyspark_df['Parch'] + pyspark_df['SibSp']).\\\n",
        "            drop('Parch', 'SibSp')"
      ],
      "metadata": {
        "id": "vPSTyyxFvZrY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop unnecessary colummns"
      ],
      "metadata": {
        "id": "2ieqldiRmCDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = pyspark_df.drop('PassengerID', 'Cabin', 'Name', 'Ticket', 'Title')"
      ],
      "metadata": {
        "id": "HXeQfnObvlRF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNheSsGdvoDE",
        "outputId": "7d464847-d16b-4de7-cff1-1a605425ad10"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-------+--------+----------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|FamilySize|\n",
            "+--------+------+------+----+-------+--------+----------+\n",
            "|       0|     3|  male|22.0|   7.25|       S|         1|\n",
            "|       1|     1|female|38.0|71.2833|       C|         1|\n",
            "|       1|     3|female|26.0|  7.925|       S|         0|\n",
            "|       1|     1|female|35.0|   53.1|       S|         1|\n",
            "|       0|     3|  male|35.0|   8.05|       S|         0|\n",
            "+--------+------+------+----+-------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in pyspark_df.columns:\n",
        "    print(col.ljust(20), pyspark_df.filter(pyspark_df[col].isNull()).count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRzAmCsRvpzg",
        "outputId": "494ed449-2926-4119-efee-e1dae2714bd7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survived             0\n",
            "Pclass               0\n",
            "Sex                  0\n",
            "Age                  0\n",
            "Fare                 0\n",
            "Embarked             0\n",
            "FamilySize           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Models"
      ],
      "metadata": {
        "id": "kD3u3D1cmXH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator"
      ],
      "metadata": {
        "id": "HULUQWuFvvR8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stringIndex = StringIndexer(inputCols=['Sex', 'Embarked'],\n",
        "                       outputCols=['SexNum', 'EmbNum'])\n",
        "\n",
        "stringIndex_model = stringIndex.fit(pyspark_df)\n",
        "\n",
        "pyspark_df_ = stringIndex_model.transform(pyspark_df).drop('Sex', 'Embarked')"
      ],
      "metadata": {
        "id": "45ggphJCmrqh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df_.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YQ_BDI-mwSH",
        "outputId": "e0d009a2-0688-4375-89a9-b6b4aa1a2009"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+-------+----------+------+------+\n",
            "|Survived|Pclass| Age|   Fare|FamilySize|SexNum|EmbNum|\n",
            "+--------+------+----+-------+----------+------+------+\n",
            "|       0|     3|22.0|   7.25|         1|   0.0|   0.0|\n",
            "|       1|     1|38.0|71.2833|         1|   1.0|   1.0|\n",
            "|       1|     3|26.0|  7.925|         0|   1.0|   0.0|\n",
            "|       1|     1|35.0|   53.1|         1|   1.0|   0.0|\n",
            "|       0|     3|35.0|   8.05|         0|   0.0|   0.0|\n",
            "+--------+------+----+-------+----------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_asmbl = VectorAssembler(inputCols=pyspark_df_.columns[1:],\n",
        "                           outputCol='features')\n",
        "\n",
        "pyspark_df_ = vec_asmbl.transform(pyspark_df_).select('features', 'Survived')\n",
        "pyspark_df_.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knubMVsIm4a9",
        "outputId": "f6f6e3e6-9bca-4c51-fbb0-af447987f555"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+\n",
            "|features                      |Survived|\n",
            "+------------------------------+--------+\n",
            "|[3.0,22.0,7.25,1.0,0.0,0.0]   |0       |\n",
            "|[1.0,38.0,71.2833,1.0,1.0,1.0]|1       |\n",
            "|[3.0,26.0,7.925,0.0,1.0,0.0]  |1       |\n",
            "|[1.0,35.0,53.1,1.0,1.0,0.0]   |1       |\n",
            "|[3.0,35.0,8.05,0.0,0.0,0.0]   |0       |\n",
            "+------------------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = pyspark_df_.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "x5-dEN2Um-mx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD59ZvZunQIn",
        "outputId": "418fb308-27dd-4784-da77-2baa42aaefbb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+--------+\n",
            "|features                         |Survived|\n",
            "+---------------------------------+--------+\n",
            "|(6,[0,1],[2.0,33.02272727272727])|0       |\n",
            "|(6,[0,1],[2.0,33.02272727272727])|0       |\n",
            "|(6,[0,1],[3.0,19.0])             |0       |\n",
            "|(6,[0,1],[3.0,25.0])             |1       |\n",
            "|(6,[0,1],[3.0,36.0])             |0       |\n",
            "+---------------------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Tree (Rf)"
      ],
      "metadata": {
        "id": "OVAym2fKnp9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol='Survived')\n",
        "model = rf.fit(train_df)\n",
        "pred = model.transform(test_df)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Survived')\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "auroc = evaluator.evaluate(pred, {evaluator.metricName: \"areaUnderROC\"})\n",
        "aupr = evaluator.evaluate(pred, {evaluator.metricName: \"areaUnderPR\"})\n",
        "\n",
        "print('Area under ROC curve:', auroc)\n",
        "print('Area under PR curve:', aupr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I8QT9mcUrh5",
        "outputId": "da5bbb19-d9d4-4d44-cde4-d3925c501c92"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC curve: 0.8823888529770885\n",
            "Area under PR curve: 0.7806890892271653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning with CrossValidator and evaluation:"
      ],
      "metadata": {
        "id": "bM63P3KQH3Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfparamGrid = (ParamGridBuilder()\n",
        "               .addGrid(rf.maxDepth, [2, 4, 5])\n",
        "               .addGrid(rf.numTrees, [5, 10, 20, 100])\n",
        "             .build())"
      ],
      "metadata": {
        "id": "rgx-fYtlHqHq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluatorRF=BinaryClassificationEvaluator(labelCol='Survived')\n",
        "\n",
        "cv = CrossValidator(estimator = rf,\n",
        "                      estimatorParamMaps = rfparamGrid,\n",
        "                      evaluator = evaluatorRF,\n",
        "                      numFolds = 5)\n",
        "\n",
        "rfcv=cv.fit(train_df)"
      ],
      "metadata": {
        "id": "YenCu9dPHzgw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test documents with CrossValidation models\n",
        "predictions=rfcv.bestModel.transform(test_df)\n",
        "evaluatorRF.evaluate(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYKJG69OIEFz",
        "outputId": "e915e168-4d0d-48d1-a75b-8f7297bec509"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8854772678302091"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auroc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n",
        "aupr= evaluatorRF.evaluate(predictions, {evaluatorRF.metricName: \"areaUnderPR\"})\n",
        "print('Area under ROC curve: ',auroc)\n",
        "print('Area under PR curve: ',aupr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNyfMCy0I5p7",
        "outputId": "54c49ba5-d34c-4537-9b7d-48ede0efbc74"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC curve:  0.8854772678302092\n",
            "Area under PR curve:  0.8438690592755584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can get the accuracy and F1 score using MulticlassClassificationEvaluator\n",
        "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "rf_accuracy = multi_evaluator.evaluate(predictions)\n",
        "print(\"Accuracy of RandomForestClassifier is = \", (rf_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0mSABu2JCqS",
        "outputId": "d30352f8-27cc-4bba-d3a8-633eefd4f6ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of RandomForestClassifier is =  0.8401639344262295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using sklearn for classification report\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = predictions.select(['Survived']).collect()\n",
        "y_pred = predictions.select(['prediction']).collect()\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcuCGoivJFho",
        "outputId": "4ba179d7-c803-4f90-9d4d-a05139326135"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87       153\n",
            "           1       0.80      0.77      0.78        91\n",
            "\n",
            "    accuracy                           0.84       244\n",
            "   macro avg       0.83      0.83      0.83       244\n",
            "weighted avg       0.84      0.84      0.84       244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "- Evaluation Metrics: AUROC Measures how well the model distinguishes between classes. AUPR Assesses the balance between precision and recall. A high score shows the model accurately predicts true positives\n",
        "\n",
        "- Cross-validation dividing the dataset into multiple folds and training/testing on different folds, uses a 5-fold cross-validation to fine-tune the hyperparameters (maxDepth and numTrees) to ensures the model is not overfitting\n",
        "\n",
        "- The scores we got for the metrics were higher (just a bit ðŸ˜‚) using hyperparameter tuning with CrossValidator than the ones we reached with the baseline model."
      ],
      "metadata": {
        "id": "ll8CW0tMLDXp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lm5Ea2fWYpP"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}